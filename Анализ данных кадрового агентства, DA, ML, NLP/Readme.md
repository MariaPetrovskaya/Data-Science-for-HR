12 марта
добавлена презентация и version 2
**По новой версии (Version 2)**

**Примечания для тимлида Ольги**:



*   Работа по проекту продолжается.
*   Внутри больших разделов свои копии датасетов, их можно запускать автономно (копируется датасет после загрузки с переименованными столбцами).  


**Добавлено по сравнению с версией 1**:




*  В раздел EDA добавлено "ручное" разделение по категориям, анализ средних показателей просмотра и конверсии по категориям.
*  В раздел NLP добавлен большой раздел с кластеризацией заголовков вакансий КNN (и с визуализацией в Wordcloud) (посмотреть, как тот же самый вопрос классификации должностей можно воплотить с помощью машинного обучения). Названия профессий классифицируются на 22 и на 10 категорий, рассматриваются результаты, что вошло в каждый класс. В целом, классификация KMM по итогам получается, но уступает по классификации по алгоритму, написанному человеком. В общем, это такое ответвление проекта которое интересно не всем, его можно держать в свернутом виде, на запуск кода до и после не повлияет.

*   В качестве наиболее успешного решения остается предобученная LLM для создания embedding (в данном случае русская версия BERT) и бустинговая модель работающая с категориями (в данном случае Catboost). Пробовала несколько вариантов, меняя размер выборки (1000, 1200), предобработку (замена пропусков в "дополнительные-additional..."). Файлы удачных комплектов (features, target) выкладываю, метрики по результатам их применения указаны в комментариях после кода.
*   Я не успела попробовать заменить пропуски в  "salary_" в датасете средним по категории и заново посчитать такую версию. Если это улучшит метрику - оставить. Пока что модель альтруистична и ничего не знает про зарплату.


По предыдущей версии 
**Примечания для тимлида Ольги**: 


*   Работа по проекту продолжается, по мере улучшения версии будет обновляться
*   Примечания внутри кода и маркдауны пока на runglish, привожу к единому виду на русский язык и орфография не везде проверена. 
*   Внутри разделов я часто делаю копию основного датасета и работаю с ней, чтобы уменьшить количество перезапусков. Если это мешает или неправильно - можно исправить. 
*   Раздел EDA может быть улучшен, он на данный момент минимальный - я там только основную метрику обосновала, а улучшать можно бесконечно и есть множество идей. Например, видела хорошую идею с разделением вакансий на категории, которую хочется воплотить с улучшениями.
*   Раздел NLP с "мешком слов" - сейчас в этой части выбран относительно простой вариант с визуализацией в Wordcloud. В основном, рали забавной визуализации. По хорошему тут надо считать например TF-IDF, подбирать модель и считать метрику регрессии (аналогично части с BERT и далее). А если идти по логике классификации, то интересно пересечь словари плохой и хорошей конверсии, убрать вообще все общие для них слова, и оставить только токены специфичные для плохого и хорошего (попробовать интересно, но в остатке может оказаться какой-то не интерпретируемый рандом) 
*   Есть огромное количество NLP методов более изощренных, чем "мешок слов" и не таких долгоработающих как трансформеры, их бы я попробовала в отдельном разделе. 
*   Предобученная LLM для создания embedding (в данном случае русская версия BERT) и бустинговая модель работающая с категорими (в данном случае Catboost) - перспективная комбинация, но для повышения метрики можно менять параметры и версию BERT и параметры бустинга. Или увеличить датасет. 
*   По ходу проекта много проверочного кода, где я вывожу промежуточные результаты, можно его убрать или закомментировать. 
*   Я не нашла решение нужны ли признаки "salary_" в датасете и чем заменить пропуски. Можно попробовать заменить пропуски средним по категории и заново посчитать такую версию. Если это улучшит метрику - оставить. 



