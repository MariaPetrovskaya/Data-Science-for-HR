{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "тут изначально 4 признака из текстовых полей датасета, сливаются в один и заполнялись пропуски, там где они были."
      ],
      "metadata": {
        "id": "MsY50zm3T_9J"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zMiQvfOQVAjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1['additional']= data1['additional'].fillna('или')\n",
        "#датасет и так невелик, поэтому нашла выход чем нейтральным заполнить пропуски в \"additional\""
      ],
      "metadata": {
        "id": "cpShIwQ99PFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1['language'] = data1['mandatory']+data1['work_conditions']+data1['job_title']+data1['additional']\n"
      ],
      "metadata": {
        "id": "ZgLMusSChGRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "дальше при обучении была токенизация и ВЕRT. На всякий случай добавлю их, т.к. не очень уверена что именно может быть подключено в проде.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5yYnLrkkVBgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/sbert_large_mt_nlu_ru\")\n",
        "model = AutoModel.from_pretrained(\"ai-forever/sbert_large_mt_nlu_ru\")"
      ],
      "metadata": {
        "id": "FV1Y1XEAkbl3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "afd4cc1141c548faa995b73010eef30d",
            "deeb09e13c284bf59cdc378d94cb04d5",
            "f15df08e5b2a41608bc4931f62d7fde8",
            "60f954e6227b4485b6b04bffb6957d0c",
            "00d357cf146f467e9576cb94431ebbcb",
            "c80e84b622a94cb2aac696495967a10d",
            "9efdf263589d43398cff992fee9d9dc6",
            "2f33b5ae0cff4ae9b4162064745d0923",
            "e5edafb8e448408ca88ac6b6a038e9d1",
            "1638d99e0e7540d99ead4e39495e8fa2",
            "61f939a01c86438d8393f5f7ed8185a6",
            "d545597e4106497aad9f31525e3aa45d",
            "585c4db6c8ae4496bc20a9559ce59476",
            "403ce401b6a24b7e8ca6633f10478b81",
            "0fabfd4c3ee545228b48cf29731f167a",
            "20b813e225a44220bb54e71022f84efe",
            "eb546ac734a444a791394b9610c8fb4f",
            "2223f7ea48b34fcfb53fc0e25d41bcbc",
            "80e649f8ad4a420db20a22d9d0d2caa6",
            "363b7b1c0ee64ca7909d3df09c8f1191",
            "5a28dfb7256b4ca68a02c809f25fe7be",
            "22830ac7e88f4f82a505971812b8b567",
            "79485c55f78e4496b3aed00164e65741",
            "8c8bc6f12a26437d849868ef2a5f5ae2",
            "051d1726a0c94497a3c8cfd9d2d81442",
            "ed92453674484a5a983b2cd56289038a",
            "5c1ce99ffe624e919c627cb50c154718",
            "c4c151d27e0b484399f00e2d005b164a",
            "6bf0b3500a764610a9e7e2eb2d8a2650",
            "d7a749fbee81479c873da3aeece70683",
            "7324de19b620451fa3b33f6c53eb9fc2",
            "b91c9a94efdd41da93bc0b41e18d7ec7",
            "01badb3a7deb41289551185652ba8e55",
            "390d68038fdc49a9adc6e5769ea9626a",
            "0afc4da9db4c4a09a0a54d523ba5a093",
            "e2e23183fc214387b4a9dd8348a9ad01",
            "225a09c3eefa4f6e9e2a8bda0d290f3f",
            "2678a3ab315e467680694bc75043632c",
            "280055129e9c4fc9b55c55f4fdcd946f",
            "95f35386ee394f5ba0dd26d82629e381",
            "75cb7b5fd8f04708a5cde9c33afc2ccf",
            "1542683862b2408c81db5fe4a337c2d5",
            "24d41de8f68441d58c1fa247237c2937",
            "99254be3400140d5932896418da4bb6c",
            "216951fea78049efb69518becaa2989b",
            "60619faa4dba4c2287361d71f5ffce2d",
            "1d49de678f0240ce9772c745bd245087",
            "1f2762f912854f79bef4c48d7faea5e4",
            "4fe3095be6e448fb98419f8536aa3802",
            "179825831ea14b2baee89a329e1cb0c5",
            "a35648ee8e5f4579bd7e532a560b3f48",
            "4612ffc84d50462385afd98dab2cb592",
            "9df19a8851af423eb6619a22f6e36179",
            "520646fdb3ec412491ff4bc7921265ef",
            "e8c9bbef3269411d92fbcdc20477dbcb"
          ]
        },
        "outputId": "c8ade09e-52a3-4dd8-f294-043ecc040bbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/331 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afd4cc1141c548faa995b73010eef30d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/752 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d545597e4106497aad9f31525e3aa45d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/1.78M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79485c55f78e4496b3aed00164e65741"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "390d68038fdc49a9adc6e5769ea9626a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "216951fea78049efb69518becaa2989b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FTyCuAagWQlI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7ce110b"
      },
      "outputs": [],
      "source": [
        "tokenized = data1['language'].apply(\n",
        "    lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True))\n",
        "\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
        "\n",
        "attention_mask = np.where(padded != 0, 1, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cc1e93e"
      },
      "outputs": [],
      "source": [
        "batch_size = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "305d0021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "89ec2a2fa32640328c5f6eda59610552",
            "15608948948d4809bc206ddd4894df01",
            "3bd498b6329641d885f5e120a0b02712",
            "255120a5b7cc46ca95c268688d1a08b4",
            "0c22d47faeae4488afdbea934632cffd",
            "021e6af9f48545bab8c96ce6ae81858f",
            "cfa7f56c98614a0fb4ed6bdf4e8e02c3",
            "5ea4bdb2a38a40b5850a2ce5a9b14421",
            "da869018333045e8b2c4427428eb376c",
            "39e759db22d94ed192ceb58bba6f8eed",
            "142452503aed43aba459141001bd8ba8"
          ]
        },
        "outputId": "1159ff02-9338-4d02-a5af-c46c91bdb094"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/13 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89ec2a2fa32640328c5f6eda59610552"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Этот код ждать выполнения не обязательно, он считался в Colab около 4 часов, я выгрузила его результаты дальше как переменные\n",
        "\n",
        "batch_size = 100\n",
        "embeddings = []\n",
        "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
        "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
        "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
        "\n",
        "        with torch.no_grad():\n",
        "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
        "\n",
        "        #embeddings.append(batch_embeddings[0][:,:].numpy())\n",
        "        embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
        "        del batch\n",
        "        del attention_mask_batch\n",
        "        del batch_embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2266c71"
      },
      "outputs": [],
      "source": [
        "features = np.concatenate(embeddings)\n"
      ]
    }
  ]
}